{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec27f48",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "- Read all the comments carefully before starting attempting to solve the problems\n",
    "- Feel free to use any libraries not imported here. \n",
    "\n",
    "**Duration**  \n",
    "- Prep Time - 15 mins before the exam\n",
    "- Total Exam Time 90 Mins\n",
    "- Buffer Time - 15 mins. To be used only at the discretion of the examiner or the TAs in case of some unexpected issues\n",
    "\n",
    "--- \n",
    "\n",
    "**How to complete the exam**\n",
    "- The exam has three problems - one very easy (5 Marks), one easy (5 Marks) and one moderate (10 Marks). There are no difficult questions in this exam\n",
    "- There are answer cells at the end of each question. The exam will be first evaluated based on the answers and then the code. It is important to fill the answer cells.\n",
    "- You are expected to upload your Jupyter notebooks by 3:45 PM unless you have recieved explicit permission for late submission. \n",
    "- Each notebook should have a working code. Only questions with working codes will be evaluated\n",
    "\n",
    "--- \n",
    "\n",
    "**What not to do**\n",
    "- DO NOT rename any variables or modify the code provided to you. There are clearly marked sections that indiciate \"your code goes here\". Use those for your codes. \n",
    "- Evaluation depends on existing variables and can go wrong if they are modified in any manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bdd07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "def human_readable_size(size_in_bytes):\n",
    "    \"\"\"\n",
    "    Convert a size in bytes to a human-readable format (KB, MB, GB, etc.).\n",
    "    :param size_in_bytes: The size in bytes\n",
    "    :return: A human-readable string\n",
    "    \"\"\"\n",
    "    units = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "    size = size_in_bytes\n",
    "    for unit in units:\n",
    "        if size < 1024:\n",
    "            return f\"{size:.2f} {unit}\"\n",
    "        size /= 1024\n",
    "    return f\"{size:.2f} PB\"  # In case it exceeds petabytes\n",
    "\n",
    "def get_deep_size(obj):\n",
    "    \"\"\"Recursively calculate the memory size of an object, including nested objects.\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum(get_deep_size(k) + get_deep_size(v) for k, v in obj.items())\n",
    "    elif isinstance(obj, (list, tuple, set)):\n",
    "        size += sum(get_deep_size(i) for i in obj)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7228fa",
   "metadata": {},
   "source": [
    "## Question 1 (5 Marks)\n",
    "\n",
    "\n",
    "- You are given a basic text tokenization and tf-idf indexing pipeline\n",
    "- Improve it to include necessary preprocessing steps like lowercasing, stemming and stopword removal\n",
    "- Report the difference in vocabulary size and size of TF posting list\n",
    "- Rationale behind solving this problem: Limits the vocab size, eliminates noisy terms making retrieval more efficient. Also provides the class an opportunity to gain easy 5 marks making sure no one fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29410152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for Question 1\n",
    "\n",
    "df = pd.read_csv('/home/parth/Lab_exam/bdnews-small.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c34c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple tokenization and preprocessing pipeline\n",
    "\n",
    "def preprocess_text_simple(token_list):\n",
    "    preprocessed_token_list = [w for w in token_list]\n",
    "    return preprocessed_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tokenization\n",
    "\n",
    "s = time.time()\n",
    "df['tokens'] = df['text'].apply(lambda x: word_tokenize(x))\n",
    "print(f\"Tokenization complete in {(time.time() - s)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use simple preprocessing\n",
    "\n",
    "s = time.time()\n",
    "df['simple_preprocessing'] = df['tokens'].apply(lambda x: preprocess_text_simple(x))\n",
    "print(f\"Simple preprocessing complete in {(time.time() - s)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build simple tf-idf inverted index\n",
    "\n",
    "term_freq_simple = {}\n",
    "doc_freq_simple = {}\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "for id, row in df.iterrows():\n",
    "    doc_id = row.docno\n",
    "    tokens = row.simple_preprocessing\n",
    "    terms_found_in_doc = []\n",
    "    for t in tokens:\n",
    "        term_freq_simple[(doc_id, t)] = term_freq_simple.get((doc_id, t), 0) + 1\n",
    "        terms_found_in_doc.append(t)\n",
    "    \n",
    "    for t in set(terms_found_in_doc):\n",
    "        doc_freq_simple[t] = doc_freq_simple.get(t,0) + 1\n",
    "    \n",
    "inverse_doc_freq_simple = {}\n",
    "total_docs = len(df)\n",
    "for t in doc_freq_simple:\n",
    "    inverse_doc_freq_simple[t] = math.log(total_docs/doc_freq_simple[t])\n",
    "        \n",
    "print(f\"Tf-idf indexing complete in {(time.time() - s)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe88099",
   "metadata": {},
   "source": [
    "### Define your preprocessing pipeline here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(token_list):\n",
    "    '''\n",
    "    Complete this method\n",
    "    '''    \n",
    "    return preprocessed_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply your preprocessing pipeline here\n",
    "\n",
    "s = time.time()\n",
    "df['preprocessing'] = df['tokens'].apply(lambda x: preprocess_text(x))\n",
    "print(f\"Preprocessing complete in {(time.time() - s)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc915e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tf-idf inverted index with output of your preprocessing pipeline\n",
    "# Note: Read this code carefully. There are some errors and you will have to make some changes here\n",
    "\n",
    "term_freq = {}\n",
    "doc_freq = {}\n",
    "inverse_doc_freq = {}\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "for id, row in df.iterrows():\n",
    "    doc_id = row.docno\n",
    "    tokens = row.simple_preprocessing\n",
    "    terms_found_in_doc = []\n",
    "    for t in tokens:\n",
    "        term_freq[(doc_id, t)] = term_freq_simple.get((doc_id, t), 0) + 1\n",
    "        terms_found_in_doc.append(t)\n",
    "    \n",
    "    for t in set(terms_found_in_doc):\n",
    "        doc_freq[t] = doc_freq_simple.get(t,0) + 1\n",
    "    \n",
    "total_docs = len(df)\n",
    "for t in doc_freq_simple:\n",
    "    inverse_doc_freq[t] = math.log(total_docs/doc_freq_simple[t])\n",
    "\n",
    "print(f\"Tf-idf indexing with preprocessing complete in {(time.time() - s)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ab468",
   "metadata": {},
   "source": [
    "### Answer for Q1\n",
    "\n",
    "**Do not forget to fill this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f413a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this. Your answer will be evaluated based on these statistics\n",
    "\n",
    "print(\"Statistics with simple preprocessing: \\n\"\\\n",
    "     f\"Posting list size: {} \\n\"\\\n",
    "     f\"Vocab size: {}\")\n",
    "\n",
    "print(\"Statistics with new preprocessing: \\n\"\\\n",
    "     f\"Posting list size: {} \\n\"\\\n",
    "     f\"Vocab size: {}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d3871",
   "metadata": {},
   "source": [
    "# Question 2 - 10 Marks\n",
    "\n",
    "- While computing cosine similarity we usually follow the following process: \n",
    "    1. Identify the query terms by applying preprocessing pipeline\n",
    "    2. Score each document by navigating the posting lists\n",
    "    3. Sort the documents and return top K \n",
    "   \n",
    "\n",
    "- For this task you are given a working code that computes the similarity\n",
    "- The inverted index created in previous step is not efficient for this kind of scoring\n",
    "- With very minor modifications you can create a more efficient datastructure for your inverted index which will improve the querying time by many folds (Expected improvement in latency atleast 50x)\n",
    "- Implement an more efficient inverted index and the corresponding tf-idf scoring mechanism\n",
    "- Compare the runtimes for the given query for the original and updated inverted index\n",
    "- Rationale behind solving this problem: increasing querying efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aff7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is a query but a few random words stiched together in the hope of quenching the eternal thirst for knowledge\"\n",
    "\n",
    "query_tokens = word_tokenize(query)\n",
    "\n",
    "# If you successfully implemented the preprocess_text method in Q1-a, set the below variable as True\n",
    "q1_a_completed = False\n",
    "\n",
    "if not q1_a_completed:\n",
    "    \n",
    "    print(\"Using the inefficient preprocessing pipeline and corresponding tf-idf values\")\n",
    "    scores = {}\n",
    "    preprocessed_query = preprocess_text_simple(query_tokens)\n",
    "    start_time = time.time()\n",
    "    # tf-idf scoring\n",
    "    for t in preprocessed_query:\n",
    "        for posting in term_freq_simple:\n",
    "            doc_id = posting[0]\n",
    "            term = posting[1]\n",
    "            if t == term:               \n",
    "                scores[doc_id] = scores.get(doc_id, 0) + term_freq_simple[posting]*inverse_doc_freq_simple[term]\n",
    "    \n",
    "    query_processing_time = time.time() - start_time\n",
    "\n",
    "else:\n",
    "    print(\"Using the efficient preprocessing pipeline and corresponding tf-idf values from Q1-a\")\n",
    "    scores = {}\n",
    "    preprocessed_query = preprocess_text(query_tokens)\n",
    "    start_time = time.time()\n",
    "    # tf-idf scoring\n",
    "    for t in preprocessed_query:\n",
    "        for posting in term_freq:\n",
    "            doc_id = posting[0]\n",
    "            term = posting[1]\n",
    "            if t == term:\n",
    "                scores[doc_id] = scores.get(doc_id, 0) + term_freq[posting]*inverse_doc_freq[term]\n",
    "    query_processing_time = time.time() - start_time\n",
    "\n",
    "print(f\"Processed query in time {query_processing_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90859a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the improved tf-idf inverted index with output of your preprocessing pipeline (if completed Q1-A) \n",
    "# or with the output of simple preprocessing pipeline already provided\n",
    "\n",
    "## Do NOT rename these three variables\n",
    "term_freq_efficient = {}\n",
    "doc_freq_efficient = {}\n",
    "inverse_doc_freq_efficient = {}\n",
    "\n",
    "s = time.time()\n",
    "'''\n",
    "Your indexing code goes here\n",
    "'''    \n",
    "\n",
    "print(f\"Efficient Tf-idf indexing complete in {(time.time() - s)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify your scoring method to work with the updated indexing method\n",
    "\n",
    "query = \"What is a query but a few random words stiched together in the hope of quenching the eternal thirst for knowledge\"\n",
    "\n",
    "query_tokens = word_tokenize(query)\n",
    "    \n",
    "# replace this with your efficient preprocessing if Q1-A is compelete.\n",
    "# Note the pipeline used for simple scoring and efficient scoring should be same. \n",
    "# Update this only if you used the efficient preproceesing pipeline in previous step as well\n",
    "# You should get exact same scores for simple and efficient processing. Only the runtime will improve\n",
    "print(\"Preproceesing the query\")\n",
    "\n",
    "preprocessed_query = preprocess_text_simple(query_tokens) \n",
    "\n",
    "start_time = time.time()\n",
    "scores_efficient = {}\n",
    "'''\n",
    "Your scoring code goes here\n",
    "'''       \n",
    "\n",
    "updated_query_processing_time = time.time() - start_time\n",
    "\n",
    "print(f\"Processed efficient query in time {updated_query_processing_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b8552",
   "metadata": {},
   "source": [
    "### Answer for Q2\n",
    "\n",
    "**Do not forget to fill this**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processed query on simple index in time {updated_query_processing_time}\")\n",
    "print(f\"Processed query on efficient index in time {query_processing_time}\")\n",
    "try:\n",
    "    assert scores == scores_efficient\n",
    "    print(\"Looks good\")\n",
    "except AssertionError:\n",
    "    print(\"Somethings wrong, both scores should match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077e427",
   "metadata": {},
   "source": [
    "## Question 3 - 5 Marks\n",
    "\n",
    "- Further optimize the posting lists by implementing champions list\n",
    "- Chapmpions list reduces lengths of posting lists\n",
    "- GPT defines champions list as \"A champion list is a precomputed list of the top documents for each term in the inverted index, based on a certain ranking metric (e.g., term frequency or TF-IDF weight). These documents are considered the \"champions\" for the term and are more likely to be relevant in search queries involving that term.\"\n",
    "- The idea is to compress the inverted index by retaining only at-most top-K documents for each term\n",
    "- Complete this function for a specific doc_id\n",
    "- Rationale behind solving this problem: decreasing the inverted index size, with slight to no effect on ranking\n",
    "- Technically this can be solved without solving question 2. However, it will be much easier to solve if you have successfully implemented quetion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your method here\n",
    "\n",
    "def get_champions_list_based_inverted_index(tf, df):\n",
    "        \n",
    "    return tf_updated, df_updated\n",
    "\n",
    "\n",
    "term_freq_champion_list, document_freq_champion_list = get_champions_list_based_inverted_index(tf,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e8c831",
   "metadata": {},
   "source": [
    "### Answer for Q3\n",
    "\n",
    "**Do not forget to fill this**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578684be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size of original tf dictionary:  {human_readable_size(get_deep_size(term_freq_simple))} \\n\"\\\n",
    "      f\"Size of original idf dictionary: {human_readable_size(get_deep_size(inverse_doc_freq_simple))}\")\n",
    "\n",
    "print(f\"Size of original tf dictionary:  {human_readable_size(get_deep_size(term_freq_champion_list))} \\n\"\\\n",
    "      f\"Size of original idf dictionary: {human_readable_size(get_deep_size(document_freq_champion_list))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
